/* Copyright (C) 2012 Ion Torrent Systems, Inc. All Rights Reserved */

#include <iostream>
#include <sstream>
#include <fstream>
#include <stdlib.h>
#include <cassert>
#include <boost/multi_array.hpp>
#include <libgen.h>
#include <string.h>

// Analysis Utils
#include "OptArgs.h"
#include "IonErr.h"

// file-io tools
#include "ion_alloc.h"
#include "ion_util.h"

// file-io sff
#include "sff.h"
#include "sff_file.h"
#include "sff_header.h"

// recall_map[bin 0...][base (0123:ACGT)][signal(0..maxsignal-1)] = HP
typedef boost::multi_array<int, 3> recall_map_type;

using namespace std;

uint toInt(char nuc) {
  switch(nuc) {
  case 'A': return 0;
  case 'C': return 1;
  case 'G': return 2;
  default: return 3;
  }
}

uint toBase(int nuc) {
  switch(nuc) {
  case 1: return 'A';
  case 2: return 'C';
  case 3: return 'G';
  default: return 'T';
  }
}


// calibrationFile is a lookup table: [flowBin, base, signal] => HP
// HP == -1 => NA
// Format:
// flow_map: 0 0 0 0 1 1 1 1 2 2 2 2 ....
// flow_win: 50
// max_signal: 1200
// 0 0 1 0
// ...
// 5 G 398 4   << bin 5, base G (2), signal 398 => HP length 4
// ...
// Signal values range from 1..max_signal, but are actually 0..max_signal-1.
recall_map_type* 
read_recall_map_from_file(string calibrationFile, vector<int>& flow_map, int& flow_win) {
  fstream mapFile(calibrationFile.c_str(), fstream::in);
  string label;
  int max_signal;

  mapFile >> skipws >> label;
  assert(label == "flow_map:");

  string line;
  getline(mapFile, line);
  istringstream line_stream(line, ios_base::in);
  while (line_stream.good()) {
    int bin_val;
    line_stream >> bin_val;
    flow_map.push_back(bin_val);
  }

  mapFile >> skipws >> label >> flow_win;
  assert(label == "flow_win:");

  mapFile >> skipws >> label >> max_signal;
  assert(label == "max_signal:");

  // allocate a 3D array that's bin count x 4 x max_signal
  recall_map_type* rmap = new recall_map_type(boost::extents[flow_map.size()][4][max_signal]);
  assert(rmap->shape()[0] == flow_map.size());

  while (mapFile.good()) {
    int bin, signal, hp;
    char base;
    mapFile >> skipws >> bin >> base >> signal >> hp;
    (*rmap)[bin][toInt(base)][signal-1] = hp;
  }
  mapFile.close();

  return rmap;
}

void usage() {
  cout << "Recall - Recall bases in an SFF based on recalibrated signal values." << endl 
       << "         Results are written to disk with a suffix of '.rc.sff'." << endl << endl;
  cout << "Usage: " << endl
       << "  Recall -w calibration.txt[,c2.txt[,...]] in.sff [in2.sff ...]" << endl << endl
       << "Options:" << endl
       << "  -h,--help              this message" << endl
       << "  -w,--calibration-file  file produced by R script that maps signal value to HPs" << endl
       << "                         If multiple comma separated then use first callibration for first SFF, etc." << endl
       << "  -m,--merged-sff-file   merge all SFF outputs into a single file" << endl
       << "  -o,--out-dir           directory to write SFF files (defaults to directory of input file)" << endl;
  exit(1);
}

int main(int argc, const char *argv[]) {

  // Options handling
  OptArgs opts;
  opts.ParseCmdLine(argc, argv);
  bool help;
  string outdir, mergedSFFFile;
  vector<string> calibrationFiles;
  vector<string> sffFiles;
  vector<string>::iterator sit;
  vector<string>outfiles;

  opts.GetOption(help,"false", 'h', "help");
  opts.GetOption(calibrationFiles,"",'w',"calibration-file");
  opts.GetOption(outdir,"",'o',"out-dir");
  opts.GetOption(mergedSFFFile,"",'m',"merged-sff-file");
  opts.GetLeftoverArguments(sffFiles);

  if (help || calibrationFiles.empty() || calibrationFiles.front().empty())
    usage();

  vector<string>::iterator calibrationFile = calibrationFiles.begin();
  int grand_total_reads = 0;

  // iterate over each sff file on the command line
  for (sit=sffFiles.begin(); sit != sffFiles.end(); sit++) {

    // read in the calibration file generated by the R fitting code
    vector<int> flow_map;
    int flow_win;
    recall_map_type* rmap = read_recall_map_from_file((*calibrationFile), flow_map, flow_win);
    int max_bin = rmap->shape()[0] - 1;
    int max_sig = rmap->shape()[2] - 1;

    cerr << "Read calibration file " << (*calibrationFile) << " with lookup table (" << rmap->shape()[0] << ","
	 << rmap->shape()[1] << "," << rmap->shape()[2] << ")" << endl;

    // determine the output file, which replace .sff with .rc.sff and changes the output directory, if one is specified.
    string infile(*sit);		// /dir/file.sff
    string outfile;
    size_t infile_dot = infile.rfind('.'); 
    if (infile_dot == infile.npos || infile.substr(infile_dot) != ".sff")
      ION_ABORT(string("File: ")+infile+" is missing .sff extension");

    size_t infile_slash = infile.rfind('/');
    if (infile_slash == infile.npos) 
      infile_slash = 0;
    else
      infile_slash++;

    if (outdir.size()) 
      outfile = outdir + "/" + infile.substr(infile_slash,infile_dot-infile_slash);
    else
      outfile = infile.substr(0,infile_dot);
    outfile += ".rc.sff";
    outfiles.push_back(outfile);

    // open the SFF for reading
    sff_file_t* sff_file_in = sff_fopen(infile.c_str(), "r", NULL, NULL);
    sff_t* sff = NULL;

    // open the SFF for writing
    sff_file_t* sff_file_out = sff_fopen(outfile.c_str(), "w", sff_file_in->header, NULL);

    cerr << "Reading SFF " << infile << endl
	 << "Writing SFF " << outfile << endl;

    // tallies
    grand_total_reads += sff_file_in->header->n_reads;
    unsigned int read_count = 1;
    int insertion_count = 0;
    int deletion_count = 0;

    // iterate over each read in the SFF
    while(NULL != (sff = sff_read(sff_file_in))) {

      if (read_count % 100000 == 0 || read_count == sff->gheader->n_reads)
	cerr << read_count << ": " 
	     << (insertion_count * 1.0 / read_count) << " ins/read, " 
	     << (deletion_count * 1.0 / read_count) << " del/read"
	     << endl;

      uint16_t* flowgram = sff->read->flowgram;

      // importantly, sff->read contains the following that will be updated
      //    uint8_t* sff->read->flow_index;
      //    ion_string_t* sff->read->bases;
      //    ion_string_t* sff->read->quality;

      vector<int> new_flow_index;
      string new_bases;
      string new_qualities;

      int flow_idx = 0;		// flow_idx is the number of flows to the next non-zero HP
      int old_base_idx = 0;	// index into sff->read->bases and quality

      // iterate over each signal in the read
      for (uint32_t i=0; i < sff->gheader->flow_length; i++) {
	flow_idx++;

	int newFlow;		// a new flow is just intended to
				// genericize binning based on
				// absolute flow index or
				// base-specific flow index.  Usually
				// this is just identity.
	if (i < flow_map.size())
	  newFlow = flow_map[i];
	else
	  newFlow = flow_map.back();

	int flowBin = newFlow / flow_win;
	if (flowBin > max_bin)
	  flowBin = max_bin;

	char flowBase = sff->gheader->flow->s[i];
	int flowBaseInt = toInt(flowBase);

	int flowSignal = flowgram[i];

	int oldHP = (flowSignal+50) / 100; // by convention.  flowSignals are fixed so this always works.
	assert(!oldHP || sff->read->bases->s[old_base_idx] == flowBase); // make sure we're tracking the old read

	// truncate observed signal to max from model
	if (flowSignal > max_sig)
	  flowSignal = max_sig;

	// the new predicted HP as a function of flow index (bin), base and signal
	int newHP = (*rmap)[flowBin][flowBaseInt][flowSignal];

	// -1 means that there is no prediction for this context.
	if (newHP == -1)
	  newHP = oldHP;

	if (newHP > 0) {
	  // add newHP bases to sequence
	  new_bases += string(newHP, flowBase);

	  // Copy the old quality scores. KLUDGE: if newHP > oldHP
	  // then reproduce the first quality score.  if newHP < oldHP then drop the extras.
	  if (newHP > oldHP) {
	    insertion_count++;
	    if (oldHP > 0) {
	      new_qualities += string(newHP-oldHP, sff->read->quality->s[old_base_idx]);
	      new_qualities.append(sff->read->quality->s+old_base_idx, oldHP);
	    }
	    else {
	      // there are no qualities to copy.  Use "I" because that's what Nils did!
	      new_qualities += string(newHP, 'I');
	    }
	  }
	  else {
	    if (newHP < oldHP)
	      deletion_count++;
	    new_qualities.append(sff->read->quality->s+old_base_idx, newHP);
	  }

	  // update flow index.  first position is number of skipped flows.
	  // remaining bases are zero because we're already at the designated flow.
	  new_flow_index.push_back(flow_idx);
	  new_flow_index.insert(new_flow_index.end(), newHP-1, 0);
	  flow_idx=0;		// reset for next base
	}

	// update our offset in sff->read->bases
	old_base_idx += oldHP;
      }

      // update sff with new values using ion_string
      ion_string_destroy(sff->read->bases);
      sff->read->bases = ion_string_init(new_bases.size()+1);
      copy(new_bases.begin(), new_bases.end(), sff->read->bases->s);
      sff->read->bases->l = new_bases.size();
      sff->read->bases->s[sff->read->bases->l]='\0';

      ion_string_destroy(sff->read->quality);
      sff->read->quality = ion_string_init(new_qualities.size()+1);  assert(new_qualities.size()==new_bases.size());
      copy(new_qualities.begin(), new_qualities.end(), sff->read->quality->s);
      sff->read->quality->l = new_qualities.size();
      sff->read->quality->s[sff->read->quality->l]='\0';

      free(sff->read->flow_index);
      sff->read->flow_index = (uint8_t*)ion_malloc(sizeof(uint8_t)*new_flow_index.size(), __func__, "sff->read->flow_index");
      assert(new_flow_index.size()==new_bases.size());
      copy(new_flow_index.begin(), new_flow_index.end(), sff->read->flow_index);

      // update the number of bases in the read header.  the rest of the read header is unchanged.
      sff->rheader->n_bases = new_bases.size();

      // write it to file
      sff_write(sff_file_out, sff);

      // cleanup
      sff_destroy(sff);

      read_count++;
    }

    sff_fclose(sff_file_in);
    sff_fclose(sff_file_out);

    delete rmap;

    calibrationFile++;
  }


  if (!mergedSFFFile.empty()) {

    // if no specified directory, then prepend outdir
    size_t mergefile_slash = mergedSFFFile.rfind('/');
    if (mergefile_slash == mergedSFFFile.npos) 
      if (outdir.size())
	mergedSFFFile = outdir + "/" + mergedSFFFile;

    // copy the header from the first SFF
    sff_file_t* sff_file_1 = sff_fopen(outfiles.front().c_str(), "r", NULL, NULL);
    sff_header_t* merged_header = sff_header_clone(sff_file_1->header);
    merged_header->n_reads = grand_total_reads;
    sff_fclose(sff_file_1);

    // open new combined output 
    sff_file_t* sff_merged_out = sff_fopen(mergedSFFFile.c_str(), "w", merged_header, NULL);
    cerr << "Merging " << outfiles.size() << " files into " << mergedSFFFile << endl;

    // combine all the SFF files into one
    for (vector<string>::iterator outfileI = outfiles.begin(); outfileI != outfiles.end(); outfileI++) {
      sff_file_t* sff_file = sff_fopen((*outfileI).c_str(), "r", NULL, NULL);

      cerr << "Copying " << sff_file->header->n_reads << " records from " << (*outfileI) << endl;

      // make sure key and flow are the same
      if (sff_file->header->flow_length != merged_header->flow_length ||
	  sff_file->header->key_length != merged_header->key_length ||
	  strncmp(sff_file->header->flow->s, merged_header->flow->s, merged_header->flow_length) != 0 ||
	  strncmp(sff_file->header->key->s, merged_header->key->s, merged_header->key_length) != 0) {
	ION_ABORT(string("File ")+(*outfileI)+" has a different global header");
      }

      // iterate through all SFF entries simply writing them back to file
      sff_t* sff = NULL;
      while(NULL != (sff = sff_read(sff_file))) {
	sff_write(sff_merged_out, sff);
	sff_destroy(sff);
      }

      sff_fclose(sff_file);

      // remove individual files
      unlink((*outfileI).c_str());
    }

    cerr << "Finished copying a total of " << merged_header->n_reads << " records." << endl;
    sff_fclose(sff_merged_out);
    sff_header_destroy(merged_header);
  }
}
